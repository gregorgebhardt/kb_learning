---
# DEFAULT
name: "DEFAULT"
repetitions: 3
iterations: 150
path: "data/ppo"
gui: false

params:
  sampling:
    num_kilobots: 10
    num_workers: 24
---
name: "test"
iterations: 200

params:
  sampling:
    w_factor: 1.0
    num_kilobots: 10
    num_worker_steps: 250
    environment: absolute
    light_type: dual
    done_after_steps: 125
  policy:
#    type: 'mean_mlp'
    me_size: [256, 256]
    mlp_size: [256, 256]
  ppo:
    learning_rate: 6.e-4
    gamma: 0.99
    lambda: 0.95
    clip_range: 0.1
    num_threads: 6

#list:
#  sampling:
#    w_factor: [.0, .5, 1.]
---
name: "eval_relative_env"

params:
  sampling:
    num_kilobots: 10
    num_worker_steps: 500
    environment: 'relative'
  policy:
    mlp_size: [128, 128]
  ppo:
    learning_rate: 1.e-4

list:
  sampling:
    w_factor: [.0, .5, 1.]
---
name: "eval_absolute_env"
iterations: 100

params:
  sampling:
    num_kilobots: 10
    num_worker_steps: 250
    environment: 'absolute'
    done_after_steps: 125
    policy:
      me_size: [256, 256]
      mlp_size: [256, 256]
    ppo:
      learning_rate: 6.e-4
      gamma: 0.99
      lambda: 0.95
      clip_range: 0.1
---
name: "eval_policy_type"
iterations: 100
repetitions: 10

params:
  sampling:
    num_kilobots: 10
    num_worker_steps: 250
    environment: 'relative'
    done_after_steps: 125
  policy:
    me_size: [256, 256]
    mlp_size: [256, 256]
  ppo:
    learning_rate: 6.e-4
    gamma: 0.99
    lambda: 0.95
    clip_range: 0.1

grid:
  sampling:
    w_factor: [.0, .5, 1.]
  policy:
    type: ['mlp', 'me_mlp', 'mean_mlp', 'mean_var_mlp']

---
name: "eval_num_kilobots"
grid:
  sampling:
    num_kilobots: [5, 10, 15]
    w_factor: [.0, .5, 1.]
---
name: "eval_direct_input"

params:
  policy:
    use_mean_embedding: False
    mlp_size: [128, 128, 128, 128]

grid:
  sampling:
    num_kilobots: [5, 10, 15]