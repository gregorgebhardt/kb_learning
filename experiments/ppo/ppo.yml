---
# DEFAULT
name: "DEFAULT"
repetitions: 3
iterations: 150
path: "data/ppo"
gui: false

params:
  sampling:
    num_kilobots: 10
    num_workers: 24
---
name: "test"
iterations: 200

params:
  sampling:
    w_factor: 1.0
    num_kilobots: 10
    num_worker_steps: 250
    environment: absolute
    light_type: dual
    done_after_steps: 125
  policy:
#    type: 'mean_mlp'
    me_size: [256, 256]
    mlp_size: [256, 256]
  ppo:
    learning_rate: 6.e-4
    gamma: 0.99
    lambda: 0.95
    clip_range: 0.1
    num_threads: 6

#list:
#  sampling:
#    w_factor: [.0, .5, 1.]
---
name: "eval_relative_env"

params:
  sampling:
    num_kilobots: 10
    num_worker_steps: 500
    environment: 'relative'
  policy:
    mlp_size: [128, 128]
  ppo:
    learning_rate: 1.e-4

list:
  sampling:
    w_factor: [.0, .5, 1.]
---
name: "eval_absolute_env"
iterations: 100

params:
  sampling:
    num_kilobots: 10
    num_workers: 24
    num_worker_steps: 250
    environment: 'absolute'
    done_after_steps: 250
  policy:
    swarm_network_size: [64, 64]
    light_network_size: null
    objects_network_size: null
    concat_network_size: [64]
  ppo:
    learning_rate: 6.e-4
    gamma: 0.99
    lambda: 0.95
    clip_range: 0.2
---
name: "eval_policy_type"
iterations: 100
repetitions: 10

params:
  sampling:
    num_kilobots: 10
    num_worker_steps: 250
    environment: 'relative'
    done_after_steps: 125
  policy:
    swarm_network_size: [256, 256]
    light_network_size: null
    objects_network_size: null
    concat_network_size: [256, 256]
  ppo:
    learning_rate: 6.e-4
    gamma: 0.99
    lambda: 0.95
    clip_range: 0.1

grid:
  sampling:
    w_factor: [.0, .5, 1.]
  policy:
    type: ['mlp', 'me_mlp', 'mean_mlp', 'mean_var_mlp']

---
name: "eval_network_size"

params:
  sampling:
    num_kilobots: 10
    num_workers: 16
    num_worker_steps: 500
    environment: 'absolute'
    done_after_steps: 250
  policy:
    swarm_network_size: [64]
    light_network_size: null
    objects_network_size: null
    concat_network_size: [64]
  ppo:
    learning_rate: 6.e-4
    gamma: 0.99
    lambda: 0.95
    clip_range: 0.2

grid:
  policy:
    swarm_network_size: [[64], [128], [64, 64]]
    concat_network_size: [[64], [128], [64, 64]]
---
name: "eval_direct_input"

params:
  policy:
    use_mean_embedding: False
    mlp_size: [128, 128, 128, 128]

grid:
  sampling:
    num_kilobots: [5, 10, 15]

---
name: 'create_model'
iterations: 1
repetitions: 1

params:
  sampling:
    num_kilobots: 10
    num_workers: 1
    num_worker_steps: 250
    num_minibatches: 1
    environment: 'absolute'
    done_after_steps: 125
  policy:
    swarm_network_size: [256, 256]
    light_network_size: [256, 256]
    objects_network_size: null
    concat_network_size: [256, 256]
    ppo:
      learning_rate: 6.e-4
      num_train_epochs: 1
      gamma: 0.99
      lambda: 0.95
      clip_range: 0.1
