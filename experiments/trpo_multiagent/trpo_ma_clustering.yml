---
# DEFAULT
name: "DEFAULT"
repetitions: 4
iterations: 150
path: "data/trpo_ma"
gui: false

params: {}

env_config:
  !EvalEnv
  width: 1.
  height: 1.
  resolution: 600

  objects:
    - !ObjectConf
      idx: 0
      shape: square
      width: .08
      height: .08
      init: random
    - !ObjectConf
      idx: 0
      shape: square
      width: .08
      height: .08
      init: random
    - !ObjectConf
      idx: 0
      shape: square
      width: .08
      height: .08
      init: random
    - !ObjectConf
      idx: 0
      shape: square
      width: .08
      height: .08
      init: random
    - !ObjectConf
      idx: 0
      shape: square
      width: .08
      height: .08
      init: random
    - !ObjectConf
      idx: 0
      shape: square
      width: .08
      height: .08
      init: random
    - !ObjectConf
      idx: 0
      shape: square
      width: .08
      height: .08
      init: random
    - !ObjectConf
      idx: 0
      shape: square
      width: .08
      height: .08
      init: random
    - !ObjectConf
      idx: 0
      shape: square
      width: .08
      height: .08
      init: random
    - !ObjectConf
      idx: 0
      shape: square
      width: .08
      height: .08
      init: random

  kilobots: !KilobotsConf
    num: 10
    mean: random
    std: .03

---
name: test
#iterations: 250
#repetitions: 5

params:
  sampling:
    reward_function: fisher_clustering
    agent_type: SimpleAccelerationControlKilobot
    num_objects: 8
    timesteps_per_batch: 4096
    done_after_steps: 512
  policy:
#    swarm_net_size: [64]
#    objects_net_size: [64]
    swarm_net_type: softmax
    objects_net_type: softmax
#    extra_net_size: []
    concat_net_size: [64, 64]
#    load_path: trpo_multiagent/policy.pkl
  trpo:
    gamma: .99
    lambda: .95

---
name: eval_object_sorting_random
iterations: 250
repetitions: 5

params:
  sampling:
    reward_function: object_clustering
    agent_type: SimpleVelocityControlKilobot
    num_objects: random
    timesteps_per_batch: 4096
    done_after_steps: 512
  trpo:
    gamma: .99
    lambda: .95
  policy:
    concat_net_size: [64, 64]

list:
  policy:
    type:             ['swarm', 'swarm', 'swarm',   'swarm',   'mlp']
    swarm_net_type:   ['mean',  'max',   'softmax', 'softmax', '']
    objects_net_type: ['max',   'max',   'max',     'softmax', '']

---
name: eval_object_sorting3
iterations: 250
repetitions: 5

params:
  sampling:
    reward_function: object_clustering
    agent_type: SimpleVelocityControlKilobot
    num_objects: 8
    timesteps_per_batch: 4096
    done_after_steps: 2048
  trpo:
    gamma: .99
    lambda: .95
  policy:
    concat_net_size: [64, 64]

list:
  policy:
    type:             ['swarm', 'swarm', 'swarm',   'swarm',   'mlp']
    swarm_net_type:   ['mean',  'max',   'softmax', 'softmax', '']
    objects_net_type: ['max',   'max',   'max',     'softmax', '']

---
name: eval_object_sorting2
iterations: 750
repetitions: 10

params:
  sampling:
    reward_function: object_clustering
    agent_type: SimpleVelocityControlKilobot
    num_objects: 8
    timesteps_per_batch: 4096
    done_after_steps: 512
  trpo:
    gamma: .99
    lambda: .95
  policy:
    concat_net_size: [64, 64]

list:
  policy:
    type:             ['swarm', 'swarm', 'swarm',   'swarm',   'mlp']
    swarm_net_type:   ['mean',  'max',   'softmax', 'softmax', '']
    objects_net_type: ['max',   'max',   'max',     'softmax', '']

---
name: eval_object_sorting
iterations: 250
repetitions: 10

params:
  sampling:
    reward_function: object_clustering
    agent_type: SimpleVelocityControlKilobot
    num_objects: 8
    timesteps_per_batch: 4096
    done_after_steps: 512
  trpo:
    gamma: .99
    lambda: .95
  policy:
    concat_net_size: [64, 64]

list:
  policy:
    type:             ['swarm', 'swarm', 'swarm',   'swarm',   'mlp']
    swarm_net_type:   ['mean',  'max',   'softmax', 'softmax', '']
    objects_net_type: ['max',   'max',   'max',     'softmax', '']

---
name: eval_object_sorting_amp
iterations: 350
repetitions: 5

params:
  sampling:
    reward_function: object_clustering_amp
    agent_type: SimpleVelocityControlKilobot
    num_objects: 8
    timesteps_per_batch: 4096
    done_after_steps: 512
  trpo:
    gamma: .99
    lambda: .95
  policy:
    concat_net_size: [64, 64]

list:
  policy:
    type:             ['swarm', 'swarm', 'swarm',   'swarm',   'mlp']
    swarm_net_type:   ['mean',  'max',   'softmax', 'softmax', '']
    objects_net_type: ['max',   'max',   'max',     'softmax', '']

---
name: eval_object_sorting_amp2
iterations: 500
repetitions: 10

params:
  sampling:
    reward_function: object_clustering_amp
    agent_type: SimpleVelocityControlKilobot
    num_objects: 8
    timesteps_per_batch: 4096
    done_after_steps: 512
  trpo:
    gamma: .99
    lambda: .95
  policy:
    concat_net_size: [64, 64]

list:
  policy:
    type:             ['swarm', 'swarm', 'swarm',   'swarm',   'mlp']
    swarm_net_type:   ['mean',  'max',   'softmax', 'softmax', '']
    objects_net_type: ['max',   'max',   'max',     'softmax', '']

---
name: eval_fisher_clustering
iterations: 350
repetitions: 5

params:
  sampling:
    reward_function: fisher_clustering
    agent_type: SimpleVelocityControlKilobot
    num_objects: 8
    timesteps_per_batch: 4096
    done_after_steps: 512
  trpo:
    gamma: .99
    lambda: .95
  policy:
    concat_net_size: [64, 64]

list:
  policy:
    type:             ['swarm', 'swarm', 'swarm',   'swarm',   'mlp']
    swarm_net_type:   ['mean',  'max',   'softmax', 'softmax', '']
    objects_net_type: ['max',   'max',   'max',     'softmax', '']

---
name: eval_object_clustering
iterations: 250
repetitions: 5

params:
  sampling:
    reward_function: object_clustering
    agent_type: SimpleAccelerationControlKilobot
    num_objects: 8
    timesteps_per_batch: 4096
    done_after_steps: 512
  trpo:
    gamma: .99
    lambda: .95

list:
  policy:
    type:             ['swarm', 'swarm', 'swarm',   'swarm',   'mlp']
    swarm_net_type:   ['mean',  'max',   'softmax', 'softmax', '']
    objects_net_type: ['max',   'max',   'max',     'softmax', '']

